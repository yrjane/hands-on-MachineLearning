## 13. 텐서플로에서 데이터 적재와 전처리하기

### **13.2 TFRecord 포맷**

\- TFRecord: 크기가 다른 연속된 이진 레코드를 저장하는 이진 포맷

\- 일반적으로 TFRecord는 프로토콜 버퍼를 기반으로 이진파일로 직렬화된 입력데이터가 담겨져 있음

\* 프로토콜 버퍼: 구조화된 데이터를 직렬화하는 방식, 이식성과 확장성이 좋은 이진포맷

\- TFRecord 파일로 저장한 다음 읽고 파싱할 때 텐서플로는 파싱연산을 제공하기 위한 특별한 프로토콜 버퍼 정의를 가지고 있음

**1) Example 프로토콜 버퍼**

: 데이터셋에 있는 하나의 샘플을 표현하는 프로토콜 버퍼로 TF함수로파싱 가능

Example 프로토콜 버퍼 정의에서부터 파싱까지의 단계

Example 프로토콜 버퍼 정의->Example 프로토콜 버퍼 생성->직렬화하여 TFRcord 로 저장->설명

딕셔너리를 정의->직렬화된 Example 프로토콜 버퍼 파싱

**2) Sequence Example 프로토콜 버퍼**

: 리스트의 리스트 데이터를 다룰 때 유용함

 

### 13.3 입력 특성 전처리

#### 13.3.1 원핫벡터를 사용해 범주형 특성 인코딩하기

1) 어휘사전 정의

2) 범주에 해당하는 인덱스 텐서 생성

3) 룩업테이블을 위한 초기화 객체 생성

4) 초기화 객체와 oov 버킷지정하여 룩업테이블 생성

\- oov 버킷 : 사전에 없는 범주의 경우 oov 버킷 중 하나에 할당, oov 버킷이 충분하지 않을 경우 충돌 (범주 구분 X)

\- 어휘사전이 크면 임베딩을 사용하여 인코딩하는 것이 효율적

#### 13.3.2 임베딩을 사용해 범주형 특성 인코딩하기

\- 임베딩: 범주를 표현하는 훈련 가능한 밀집 벡터

\- 각각의 범주에 대해 랜덤 벡터로 초기화 후, 임베딩 훈련 중 경사하강법을 통해 임베딩 공간 내에서 비슷한 범주끼리 가까운 위치로 이동함

![gensim을 사용하여 Word2vec 훈련](file:///C:/Users/iyr0219/AppData/Local/Temp/msohtmlclip1/01/clip_image002.jpg)

(그림 예시: 단어인베딩)

\* 단어인베딩

\- 주어진 단어 근처의 단어를 예측하도록 신경망 훈련하여 인베딩 공간에서 의미가 관련된 단어들이 함께 군집을 이룰 수 있게 함

\- 의미가 존재하는 축을 따라 임베딩 공간 안에서 조직됨(예: king –man+woman 계산 시 queen 위치와 근접)

\- 표현학습: 범주가 유용하게 표현되도록 임베딩이 훈련되는 경향

 

#### 13.3.3 케라스 전처리 층

\- keras.layers.Normalization: 특성표준화 수행

\- TextVectorization: 각 단어를 어휘사전 인덱서로 인코딩, TF-IDF 옵션이 존재하여 자주 등장하는 단어의 중요도를 줄이는 방향으로 정규화 가능

\- kearas.layers.Discretization: 수치형 데이터를 구간화하고 구간에 대해 원핫인코딩

 

### 13.4 TF 변환

\- 신경망 훈련 전 샘플 전처리 진행하면 속도 향상

\- 데이터가 작을 경우 cache() 메서드 활용, 대용량의 경우 아파치빔 혹은 스파크 사용

\- 훈련/서빙 왜곡: 모델 배포 시 데이터 전처리 과정에서 훈련 전 전처리와 앱, 브라우저에서 수행한 전처리가 차이가 나면서 버그나 성능 감소로 이어짐

\- 훈련/서빙 왜곡을 피하기 위해 모델 배포 전 동적으로 전처리 층을 추가하여 두 개의 전처리 코드 생성

\- 혹은 TF변환을 통해 전처리 함수를 한번에 정의 가능함

\- TF변환은 동일한 전처리 역할을 수행하는 텐서플로 함수를 생성하여 배포할 모델에 추가 가능하게 함

 

### 13.5 텐서플로 데이터셋 (TTFDS) 프로젝트

\- 표준 데이터셋 사용시 텐서플로 데이터셋을 사용하여 다운로드 가능

 

 

 

 