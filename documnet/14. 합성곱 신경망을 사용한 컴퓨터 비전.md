## 14. 합성곱 신경망을 사용한 컴퓨터 비전

### **14.2 합성곱 층**

\- 네트워크를 구성하는 은닉층 구조에서 앞의 합성곱층에서는 저수준 특성에 집중하고, 그 다음 합성곱층에서는 고수준 특성으로 조합 -> 계산 복잡도를 낮춰줌

#### 필터 (합성곱 커널)

\- 필터는 합성곱층에서 가중치 파라미터에 해당하며 학습단계에서 적절한 필터를 찾도록 학습함

\- 입력데이터에 필터 적용하면 필터와 유사한 이미지의 영역을 강조하는 특성맵을 출력하여 다름 층에 전달

![https://t1.daumcdn.net/cfile/tistory/99DF403C5BC97E912A](file:///C:/Users/iyr0219/AppData/Local/Temp/msohtmlclip1/01/clip_image004.png)

 



#### 여러 가지 특성 맵 쌓기

\- 하나의 합성곱 층이 입력에 여러 필터를 동시에 적용 가능하며 하나의 특성맵 안에서는 모든 뉴런이 같은 파라미터(가중치, 편향)를 공유

\- 여러 필터를 사용하면 입력에 존재하는 여러 특성을 학습 가능함

Ex) RGB

![https://t1.daumcdn.net/cfile/tistory/99C185405BC97F4D1E](file:///C:/Users/iyr0219/AppData/Local/Temp/msohtmlclip1/01/clip_image005.png)

 

 

### 14.3 풀링 층

\- 계산량과 메모리 사용량, 파라미터 수를 줄이기 위해 입력 이미지의 subsample을 생성

\- 풀링 뉴런에는 가중치가 없고 합산함수(최대, 평균 등)을 사용하여 입력값을 뽑아냄

![https://miro.medium.com/max/815/1*Sh9e6Hzx8ZcOinuLvy8Fmw.png](file:///C:/Users/iyr0219/AppData/Local/Temp/msohtmlclip1/01/clip_image007.jpg)

\- 풀링층은 입력데이터의 작은 변화에 일정수준의 불변성을 가짐. 

: 입력 데이터가 조금 변하더라도 풀링 계층 자체가 그 변화를 흡수하여 사라지게 함 

\- 일반적으로 평균 풀링층보다 의미 없는 것을 제거하고 가장 큰 특성만 유지하는 최대 풀링층이 더 성능이 좋음

\- 전역풀링층은 각 특성맵의 평균을 계산하여 각 특성맵마다 하나의 숫자를 출력

 

### 14.4 CNN 구조

![https://miro.medium.com/max/875/1*5HA3lTFOGyc5TCi4uDCHlw.png](file:///C:/Users/iyr0219/AppData/Local/Temp/msohtmlclip1/01/clip_image009.jpg)

\- 일반적으로 CNN구조는 합성곱층1 -> 풀링층1 -> …..-> 완전연결층으로 구성됨

\- 네트워크를 통과할수록 이미지는 점점 작아지지만 더 깊어짐(더 많은 특성맵)

 

#### LeNet-5

\- 처음 제로패딩으로 32*32가 된 후 패딩을 진행하지 않아 이미지 크기가 점점 작아짐

\- 평균풀링층을 사용하는데 평균을 계산한 후 한 개의 훈련가능한 가중치(trainable weight)를 곱해주고 또 한 개의 훈련가능한 바이어스(trainable bias)를 더해줌

 

#### AlexNet

![https://blog.kakaocdn.net/dn/kypYo/btqE4CT5dP2/454RR0BmLSaMobqBzUVai1/img.png](file:///C:/Users/iyr0219/AppData/Local/Temp/msohtmlclip1/01/clip_image013.jpg) 

\- 처음 합성곱층을 연속적으로 쌓아서 사용함

\- 과대적합을 줄이기 위해 1) 완전연결층에 드롭아웃 적용, 2) 데이터 증식(data augmentation) 수행

\* 데이터 증식: 이미지를 랜덤하게 이동, 회전, 조명 등을 변경하여 새로운 이미지 생성함 (물체의 위피, 방향, 크기 변화에 덜 민감)

\- 경쟁적 정규화 단계 LRN(local response normalization) 사용함 (C1, C3층 다음)

: 가장 강하게 활성화된 뉴런이 다른 특성맵에 있는 같은 위치의 뉴런끼리 정규화함

: Relu를 사용할 경우 양의 방향일 때 입력값을 그대로 사용하면서 합성곱층과 풀링층을 통과할 때 주변의 픽셀에 영향을 주게되어 이를 방지하고자 사용함

: 일반화 성능 향상시킴

 

#### GoogleLeNet

![https://blog.kakaocdn.net/dn/dtxVxa/btqzi3Yjhzq/Rshkbka1XhAhvPQypxfi41/img.png](file:///C:/Users/iyr0219/AppData/Local/Temp/msohtmlclip1/01/clip_image015.png)

\- Inception 모듈이라는 서브 네트워크로 이전 CNN구조보가 효과적으로 파라미터를 사용함

\- 네트워크의 구조: 총 27개(22개의 conv, 5개의 pooling layer)의 layer로 구성됨

1) Stem region: 신경망의 초기에는 일반적인 CNN의 은닉층 구조를 가짐(Conv - pooling - conv - pooling)

2) Inception: GoogLeNet의 핵심적인 구조로서 layer를 하나의 sub-network (Network - In - Network) 구조로 구성하여 연산량을 대폭 줄임

3) Classifier: 최종 classifier가 overfitting되거나 gradient vanishing을 방지하기 위해 중간 층에서도 부분적으로 (0.3의 가중치) 분류기 학습을 수행함

\- 인셉션 모듈은 입력값에 대해 4가지 종류의 합성곱층, 풀링층을 수행하고 4개의 결과를 채널 방향으로 합침

![img](file:///C:/Users/iyr0219/AppData/Local/Temp/msohtmlclip1/01/clip_image017.jpg)

\- 1*1 커널의 합성곱층의 역할

1) 차원 감소: 연산비용과 파라미터 개수를 줄여 훈련속도 높이고 일방화 성능 향상

2) 합성곱 층의 쌍(1*1, 3*3), (1*1, 5*5)이 두개의 층을 가진 신경망으로 이미지의 특성을 추출하는 것과 같음 

 

#### VGGNet

![https://blog.kakaocdn.net/dn/K990l/btqwDJ7C54R/664Ksm6gyTGBR1wK3YPDFk/img.png](file:///C:/Users/iyr0219/AppData/Local/Temp/msohtmlclip1/01/clip_image019.png)

\- 일반적인 CNN구조와 비슷함 연속된 합성곱층1->풀링층1->연속된 합성곱층2->풀링층2->….완전연결층

 

####  ResNet

\- 152개의 층으로 구성된 CNN구조로 잔차네트워크를 사용하여 좋은 성능 확인

\- 잔차네트워크: 특정 층의 입력값을 상위 층 출력값에 더해줄 수 있는 스킵연결을 사용한 네트워크

![https://media.vlpt.us/images/good159897/post/14c7e250-7f20-4a83-832b-045290dbb21f/ResNet%20shortcut.PNG](file:///C:/Users/iyr0219/AppData/Local/Temp/msohtmlclip1/01/clip_image002.png)

\- 네트워크 초기화시 가중치가 0에 가까워 0에 가까운 값을 출력하게 되는데, 스킵연결을 추가해잔차네트워크를 구성하면 입력과 같은 값을 출력하는 항등함수로 모델링 됨 

\- 학습 중 스킵연결 중간 블록에서 gradient가 사라져도 x를 추가로 더하여 vanishing gradient 문제를 줄일 수 있음

 

![https://blog.kakaocdn.net/dn/bdQ7nn/btqzVCKyKVV/5nkGhNvCqK9BcIgasYRxH0/img.jpg](file:///C:/Users/iyr0219/AppData/Local/Temp/msohtmlclip1/01/clip_image006.jpg)

\- VGG-19의 구조 기본으로 하며 합성곱층을 더 쌓고 이를 스킵연결로 이음

\- 특성맵의 크기와 깊이가 바뀔 때 잔차유닛에서는 스킵연결 시stride 2, 1*1 합성곱층을 통과시킴

 

#### Xception

\- GoogleLeNet 구조의 변종으로 인셉션 모듈은 “깊이별 분리 합성곱”(Depthwise Separable Convolution) 층으로 대체함

![https://blog.kakaocdn.net/dn/6S8jy/btq0pwka72b/1Jw9kCIsZpeKqDlsD9iOj0/img.png](file:///C:/Users/iyr0219/AppData/Local/Temp/msohtmlclip1/01/clip_image008.png)

\- 기존 인셉션모듈에서 1x1 합성곱층은 채널 사이의 패턴 계산하고, 3x3은 공간과 채널 패턴을 동이세 감지하는 일반적인 합성곱을 수행함 

\- Xception은 완벽히 공간상의 패턴(ex: 타원형, 직사각형) 과 채널 사이의 패턴(ex:입+코+눈=얼굴)을 독립적으로 계산하고 mapping하기 위해 고안된 모델임

1) 깊이 필터만 사용한 일반 합성곱층 

2) 공간 필터(채널당 1개)만 사용한 합성곱층으로 2개의 부분으로 구성됨

\- ![https://blog.kakaocdn.net/dn/bBD2Ib/btq0oLhCs0J/Ikelt1bkfROYzla6BHnpW1/img.png](file:///C:/Users/iyr0219/AppData/Local/Temp/msohtmlclip1/01/clip_image010.png)

 

![https://blog.kakaocdn.net/dn/biDl6K/btq0n9JQfZE/FMW4yBNvLa390ZUIQfY6X1/img.png](file:///C:/Users/iyr0219/AppData/Local/Temp/msohtmlclip1/01/clip_image012.png)

\- 일반적으로 분리합성곱층을 사용하는 것이 높은 성능을 보임

 

#### SENet

\- 인셉션 네트워크와 ResNet 구조를 확장한 모델로 원래 구조에서 모든 유닛에 작은 신경망인 SE블록을 추가하여 성능을 향상시킴

SE블록은 다음의 두 부분으로 이루어짐

1) 각 피쳐맵에 대한 전체 정보를 요약하는 Squeeze operation, 

2) 이를 통해 각 피쳐맵의 중요도를 스케일해주는 excitation operation

![Imgur](file:///C:/Users/iyr0219/AppData/Local/Temp/msohtmlclip1/01/clip_image014.png)

\- Squeeze operation 단계에서 정보를 압축하여 H , W, C 크기의 피쳐맵들을 1, 1, C크기로 만듬

\- excitation operation 단계에서 채널 간 의존성(channel-wise dependencies)을 계산하여 특성맵을 출력을 보정함(관련 없는 특성값은 낮추고 관련 있는 특성값은 유지)

\- SE블록은 어떤 모델의 네트워크에도 추가하여 사용 가능한 장점이 있음

\- 모델 성능 향상이 큰 반면 모델 복잡도와 계산 복잡도가 크게 증가하지 않다는 장점이 존재함

 

### 14.9 객체 탐지

\- 하나의 이미지에 여러 물체를 분류하고 위치를 추정하는 작업

\- CNN* 보다는 속도 면에서 완전 합성곱 신경망(FCN) 사용함

\* 사후처리를 위해 NMS 사용 필요

![img](file:///C:/Users/iyr0219/AppData/Local/Temp/msohtmlclip1/01/clip_image016.jpg)

 

#### 완전 합성곱 신경망(Fully Convolutional Networks)

\- 일반적으로 CNN 구조에는 맨 상단층에 완전연결층(dense 층)을 사용하지만 완전 합성곱 신경망에서는 이를 1×1 합성곱 계층으로 대체해 네트워크를 구성함

\- FCN은 합성곱 층만 가지므로 어떤 크기의 이미지에서도 훈련/실행 가능함

\- FCN 방식은 이미지를 딱 한 번만 처리하기 때문에 효율적

![img](file:///C:/Users/iyr0219/AppData/Local/Temp/msohtmlclip1/01/clip_image018.jpg)

 

#### YOLO(you only look once)

![갈아먹는 Object Detection [5] Yolo: You Only Look Once](file:///C:/Users/iyr0219/AppData/Local/Temp/msohtmlclip1/01/clip_image020.png)

\- 매우 빠르고 정확한 객체 탐지 구조로 실시간 비디오에 적용 가능함

1) 각 격자 셀마다 1개가 아닌 5개의 바운드 박스 출력

2) 바운드 박스 중심의 절대 좌표 예측이 아닌 격자 셀에 대한 상대 좌표 예측

3) 신경망 훈련하기 전 엥커 박스(사전 바운딩 박스)라고 불리는 5개의 대표 바운딩 박스 찾음

4) 네트워크가 다른 스케일을 가진 이미지를 사용하여 훈련함

 

### 14.10 시맨틱 분할

\- 물체가 속한 클래스에 따라 이미지의 모든 픽셀을 분류하는 작업 (클래스가 같은 물체는 구별되지 않음)

![시맨틱 분할 : 가장 강력한 컴퓨터 비전 작업](file:///C:/Users/iyr0219/AppData/Local/Temp/msohtmlclip1/01/clip_image022.jpg)

\- 일반적으로 CNN을 통과할 때 1 이상의 stride를 사용하는 층 때문에 점진적으로 위치정보를 잃는 문제 발생

\- 이를 해결하기 위해 

1) CNN를 FCN으로 변경

2) 해상도를 늘리는 업샘플링 층 추가 방법 사용

: 전치 합성곱층 사용

: 이미지에 빈 행과 열을 삽입하여 늘린 다름 일반적인 합성곱을 수행

3) 아래쪽 층에서부터 스킵 연결을 추가하여 풀링 층에서 잃은 일부 공간 정보를 복원



 